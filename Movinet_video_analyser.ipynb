{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCok+JhYk7RzOnicOgO87r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jc890/python/blob/master/Movinet_video_analyser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "YouTube Multimodal Video Analysis using MoViNet\n",
        "------------------------------------------------\n",
        "- Video action/context analysis using MoViNet\n",
        "- Placeholder for Audio + NLP conversational event detection\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import yt_dlp\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# =========================\n",
        "# CONFIGURATION\n",
        "# =========================\n",
        "YOUTUBE_URL = \"https://youtu.be/vHVR-7zURnw?si=-Q0iNtr-ucTVRWJH\"\n",
        "\n",
        "WORK_DIR = \"workspace\"\n",
        "VIDEO_PATH = f\"{WORK_DIR}/input.mp4\"\n",
        "CLIPS_DIR = f\"{WORK_DIR}/clips\"\n",
        "\n",
        "BUFFER_SECONDS = 20\n",
        "FRAME_SIZE = 172\n",
        "MAX_FRAMES = 50   # IMPORTANT: keep clips short for MoViNet\n",
        "\n",
        "MOVINET_MODEL_URL = (\n",
        "    \"https://www.kaggle.com/models/google/movinet/\"\n",
        "    \"TensorFlow2/a0-base-kinetics-600-classification/3\"\n",
        ")\n",
        "\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "os.makedirs(CLIPS_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# 1. DOWNLOAD YOUTUBE VIDEO\n",
        "# =========================\n",
        "def download_youtube_video(url):\n",
        "    ydl_opts = {\n",
        "        \"format\": \"mp4\",\n",
        "        \"outtmpl\": VIDEO_PATH,\n",
        "        \"quiet\": True\n",
        "    }\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "\n",
        "# =========================\n",
        "# 2. AUDIO + NLP PLACEHOLDER\n",
        "# =========================\n",
        "def detect_audio_events(video_path):\n",
        "    \"\"\"\n",
        "    PLACEHOLDER FOR AUDIO + NLP PIPELINE\n",
        "\n",
        "    Future:\n",
        "    - ffmpeg audio extraction\n",
        "    - Whisper ASR\n",
        "    - NLP classifier\n",
        "\n",
        "    Output format:\n",
        "    [\n",
        "        {\"event\": \"Agreement\", \"timestamp\": 60.0}\n",
        "    ]\n",
        "    \"\"\"\n",
        "    return [{\"event\": \"Agreement\", \"timestamp\": 60.0}]\n",
        "\n",
        "# =========================\n",
        "# 3. EXTRACT FRAMES\n",
        "# =========================\n",
        "def extract_frames(video_path, start_sec, end_sec):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    start_frame = int(start_sec * fps)\n",
        "    end_frame = int(end_sec * fps)\n",
        "\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "\n",
        "    frames = []\n",
        "    while cap.isOpened() and len(frames) < MAX_FRAMES:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret or cap.get(cv2.CAP_PROP_POS_FRAMES) > end_frame:\n",
        "            break\n",
        "\n",
        "        frame = cv2.resize(frame, (FRAME_SIZE, FRAME_SIZE))\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frames.append(frame)\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(frames, dtype=np.float32)\n",
        "\n",
        "# =========================\n",
        "# 4. LOAD MOVINET\n",
        "# =========================\n",
        "def load_movinet():\n",
        "    \"\"\"\n",
        "    IMPORTANT:\n",
        "    Do NOT wrap MoViNet in tf.keras.Model.\n",
        "    Call hub.KerasLayer directly with real tensors.\n",
        "    \"\"\"\n",
        "    return hub.KerasLayer(MOVINET_MODEL_URL, trainable=False)\n",
        "\n",
        "# =========================\n",
        "# 5. RUN MOVINET INFERENCE\n",
        "# =========================\n",
        "def run_movinet(video_frames):\n",
        "    \"\"\"\n",
        "    video_frames shape:\n",
        "    (T, H, W, 3)\n",
        "    \"\"\"\n",
        "\n",
        "    if len(video_frames) == 0:\n",
        "        return None\n",
        "\n",
        "    movinet = load_movinet()\n",
        "\n",
        "    # Normalize & add batch dimension\n",
        "    video_frames = video_frames / 255.0\n",
        "    video_tensor = tf.expand_dims(video_frames, axis=0)  # (1, T, H, W, 3)\n",
        "\n",
        "    outputs = movinet({\"image\": video_tensor}, training=False)\n",
        "    probs = tf.nn.softmax(outputs, axis=-1)\n",
        "\n",
        "    return int(tf.argmax(probs, axis=-1).numpy()[0])\n",
        "\n",
        "# =========================\n",
        "# 6. CLIP FINAL VIDEO\n",
        "# =========================\n",
        "def clip_video(input_video, start, end, out_path):\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-y\",\n",
        "        \"-ss\", str(start),\n",
        "        \"-to\", str(end),\n",
        "        \"-i\", input_video,\n",
        "        \"-c\", \"copy\",\n",
        "        out_path\n",
        "    ]\n",
        "    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "# =========================\n",
        "# 7. MAIN PIPELINE\n",
        "# =========================\n",
        "def main():\n",
        "    print(\"Downloading YouTube video...\")\n",
        "    download_youtube_video(YOUTUBE_URL)\n",
        "\n",
        "    print(\"Detecting audio events (placeholder)...\")\n",
        "    events = detect_audio_events(VIDEO_PATH)\n",
        "\n",
        "    for idx, event in enumerate(events):\n",
        "        t = event[\"timestamp\"]\n",
        "        start = max(0, t - BUFFER_SECONDS)\n",
        "        end = t + BUFFER_SECONDS\n",
        "\n",
        "        print(f\"\\nProcessing event '{event['event']}' at {t}s\")\n",
        "\n",
        "        frames = extract_frames(VIDEO_PATH, start, end)\n",
        "        if len(frames) == 0:\n",
        "            print(\"No frames extracted. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        action_id = run_movinet(frames)\n",
        "        print(f\"MoViNet action label ID: {action_id}\")\n",
        "\n",
        "        out_clip = f\"{CLIPS_DIR}/{event['event']}_{idx}.mp4\"\n",
        "        clip_video(VIDEO_PATH, start, end, out_clip)\n",
        "\n",
        "        print(f\"Saved clip: {out_clip}\")\n",
        "\n",
        "    print(\"\\nPipeline completed successfully.\")\n",
        "\n",
        "# =========================\n",
        "# ENTRY POINT\n",
        "# =========================\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dabazqhW4Fsk",
        "outputId": "44211b71-7ce2-46d9-c474-a890c0476230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading YouTube video...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] No supported JavaScript runtime could be found. Only deno is enabled by default; to use another runtime add  --js-runtimes RUNTIME[:PATH]  to your command/config. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one\n",
            "WARNING: [youtube] vHVR-7zURnw: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "WARNING: [youtube] vHVR-7zURnw: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting audio events (placeholder)...\n",
            "\n",
            "Processing event 'Agreement' at 60.0s\n",
            "MoViNet action label ID: 539\n",
            "Saved clip: workspace/clips/Agreement_0.mp4\n",
            "\n",
            "Pipeline completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt_dlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJAYvJ4h11Cq",
        "outputId": "ff2914d2-d478-4eb0-d31e-23d1b5c0db25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt_dlp\n",
            "  Downloading yt_dlp-2025.12.8-py3-none-any.whl.metadata (180 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/180.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m174.1/180.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.12.8-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt_dlp\n",
            "Successfully installed yt_dlp-2025.12.8\n"
          ]
        }
      ]
    }
  ]
}